<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--><html class="no-js" lang="en"><!--<![endif]-->

<head>
    <meta charset="utf-8">
<title>Learning with Neural Extensions &#8211; Nikos Karalias</title>
<meta name="description" content="Balboa Station. Watch your step">
<meta name="keywords" content="Learning with discrete functions, Neural Networks, Combinatorial optimization">

<!-- Google Analytics-->
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-D5Q79272JD"></script>
  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-D5Q79272JD');
  </script>
<!-- MathJax -->
<script type="text/javascript" async 
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>









<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Learning with Neural Extensions">
<meta property="og:description" content="Balboa Station. Watch your step">
<meta property="og:url" content="http://localhost:4000/posts/2022-12-18/Neural_Extensions.html">
<meta property="og:site_name" content="Nikos Karalias">





<link rel="canonical" href="http://localhost:4000/posts/2022-12-18/Neural_Extensions.html">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Nikos Karalias Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">



<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">   
<link rel="stylesheet" href="/assets/css/academicons.min.css">
<script src="https://kit.fontawesome.com/d3501b86e1.js" crossorigin="anonymous"></script>


    <!-- HEADER IMAGE -->
   <center>
        <span class="main-header-image">
            <a href="/"><img src="/images/header/GITS_crop.jpg"></a>
        </span>
    </center> 
    <br>
    <center>
        <span class="main-header-image">
            <h1 style="font-weight:100; font-kerning:normal"><a href="/">Nikos Karalias</a></h1>
        </span>
    </center>

    <!-- NAVIGATION -->
    <br>
    <center>
    <nav class="header-nav">
        <ul class="navigation-bar">
            <li><a href="/">HOME</a></li>
            <li><a href="/publications/">RESEARCH</a></li>
            <li><a href="/about/">ABOUT</a></li>

        </ul>
    </nav>
</center>

</head>

<!-- BODY -->
<body id="post-index">
    <!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->

    <div id="main" role="main">
        <article class="hentry">

            <div class="featured-image">
            <img src="/images/extensions/lovasz.jpg" style="width:100%">
            </div>

            <!-- MAIN -->
            <h1 class="entry-title">
                <a style= "color:rgb(255, 166, 0)" >Learning with Neural Extensions</a>
            </h1>
            <h3 class="entry-subtitle">
                <a href="http://localhost:4000" style= "color: #808080"  rel="bookmark" title="" itemprop="url">Part 1: Scalar set function extensions</a>
            </h3>

            <hr>

            <!-- POST CONTENT -->
            <div class="entry-content">
                <p>This post is meant to serve as an intuitive and practical explainer of our work on <a href="https://arxiv.org/abs/2208.04055">neural set function extensions</a>, recently presented at NeurIPS 2022. As in previous posts, I will be skipping potentially important details in the interest of brevity and understandability. For the full details, I recommend reading the paper or even just emailing me. Now, let’s get started.</p>

<h2 id="motivation">Motivation</h2>
<p>A problem that is commonly found in machine learning is that of picking an object or a set of objects that is the best with respect to a certain criterion. For example, in image classification, we predict some labels and the criterion we care about is whether the predicted labels match the true labels of the data. In strategy games like Go and chess, we have a discrete space of actions and the criterion is the reward given by the actions. In combinatorial optimization, we have a discrete space of possible configurations of objects and we are interested in the configuration that minimizes an objective function. In all of those cases, there is a function defined on a discrete space (space of labels, space of actions, space of configurations) which evaluates the quality of the <em>discrete input</em> that is provided. However, neural networks produce continuous representations which are incompatible with such functions. Furthermore, such discrete functions aren’t necessarily differentiable either, so we can’t directly use them as the loss function of our neural network. To solve such problems with NNs, we use continuous and differentiable proxies in place of the original function as a training loss, for example using the cross-entropy as a loss instead of the training accuracy. If we want to evaluate how well we are doing with respect to the original criterion, we may perform a discretization step (e.g., argmax) of the continuous representation. Alternatively, we may try to optimize the original function directly using reinforcement learning, which will discretize the continuous input (typically in a stochastic fashion through sampling).</p>

<p>In our paper on set function extensions we propose an alternative that deals both with the discrete nature of the domain of discrete functions as well as their differentiability. We show how to create continuous and differentiable extensions of discrete functions, i.e., functions compatible with continuous inputs (e.g., embeddings of neural networks) while allowing to backpropagate through them in neural network pipelines.</p>
<h2 id="concrete-setup-and-possible-approaches">Concrete setup and possible approaches</h2>
<p>Suppose that you have a neural network which produces a score vector \(\mathbf{x} \in [0,1]^{n}\) given some input problem instance (a graph, an image, etc.), which is then used to solve some downstream task. That vector could be marginal probabilities of graph nodes for some kind of node selection task, or even the class probabilities for a classification task. To make the presentation more concrete, we will treat \(\mathbf{x}\) as marginal probabilities for node selection, i.e., \(x_i\) is the probability that node \(i\) belongs to a set of nodes \(S\) that is meant to solve some graph problem (a set that optimizes some kind of objective function).</p>

<p>Now assume that you have a function \(f: 2^n \rightarrow \mathbb{R}\) whose input is any subset of \(n\) items. We can view the domain of \(f\) as the space of n-dimensional binary vectors, i.e., \(f: \{0,1\}^n \rightarrow \mathbb{R}\). I’m obviously abusing notation here to emphasize that the <em>inputs</em> of this function are <em>discrete</em>, however the <em>outputs</em> are allowed to be <em>continuous</em>. Throughout the text I will be using notation for sets and binary vectors interchangeably. 
The input domain consists of all the possible indicator vectors for all the subsets of \(n\) items we could pick. For example, let’s assume \(f\) is the cardinality function, i.e., the function that counts how many items the provided set has. Then for \(n=3\), a set \(S\) could be represented by a 3-dimensional binary vector, e.g., \(\mathbf{1}_S= \begin{bmatrix}1 &amp; 1 &amp; 0 \end{bmatrix}\). In the case of that example vector, clearly the cardinality is \(f(S) = f(\mathbf{1}_S) = 2\).</p>

<p>Naturally, that kind of function is not compatible with arbitrary \(\mathbf{x}\) due to the continuity of \(\mathbf{x}\). It doesn’t make much sense to ask what is the cardinality of (for example) \(\begin{bmatrix} 0.3 &amp; 0.5 &amp; 0.2 \end{bmatrix}\) to begin with.  If we want to find a set that minimizes (or maximizes) the function by improving the scores in \(\mathbf{x}\) in a differentiable neural network pipeline, we have to square away this incompatibility.
Here, there are certain options one would consider:</p>

<ul>
  <li>
    <p>Discretize the continuous output. We could sample with the Gumbel trick or even just threshold the values of \(\mathbf{x}\) to obtain a binary vector that represents a set. We could then use a <a href="https://www.hassanaskary.com/python/pytorch/deep%20learning/2020/09/19/intuitive-explanation-of-straight-through-estimators.html#what-is-a-straight-through-estimator">straight-through estimator</a> in the backward pass to go through the discretization procedure. While this provides a discrete vector that \(f\) is compatible with, it may only work if the function \(f\) itself <em>is differentiable</em>.</p>
  </li>
  <li>
    <p>Assume the function \(f\) is a black box, so we have no guarantees that we can differentiate through it. In that case, some kind of <a href="https://arxiv.org/abs/1711.00123">stochastic gradient estimation</a> might be our next option. For example we could use REINFORCE, i.e., sample sets \(S\) from \(\mathbf{x}\) then use the log-derivative trick to backpropagate through \(\mathbf{x}\) while treating \(f\) as the reward function.</p>
  </li>
  <li>
    <p>Use a known continuous relaxation of the function. Again, that assumes that we have access to the function and a bespoke relaxation exists. That does not 
require any discretization as the relaxation by definition accepts continuous inputs. When available, this can be a pretty good option.</p>
  </li>
</ul>

<h2 id="our-solution">Our solution</h2>
<p>These are all valid approaches that could make sense in certain scenarios. Here, we will propose a different strategy that aims to mitigate the drawbacks of the listed approaches. Namely, our approach can deal with functions in a black-box setting, 
First, we can go back to the main obstacle we started from. What does it mean to ask about the cardinality of the input (value of the discrete function) when the input is not a set (binary vector) but a vector of continuous values?  There is a way to make this question well-posed. We can treat the continuous values as parameters of a probability distribution over sets. Then we can ask what is the <em>expected value of the function</em> over the distribution of sets encoded by \(\mathbf{x}\).</p>
<h3 id="what-is-a-scalar-set-function-extension-it-is-simply-a-new-differentiable-function-mathfrakf-01n-rightarrow-mathbbr--which-extends-the-discrete-domain-of-the-original-function-to-a-continuous-domain-we-will-define-it-as-a-weighted-combination-of-evaluations-of-the-original-function-at-discrete-points-or-equivalently-as-the-expected-value-of-the-function-f-over-a-distribution-of-sets-encoded-by-mathbfx">What is a scalar set function extension? It is simply a new differentiable function \(\mathfrak{F}: [0,1]^n \rightarrow \mathbb{R}\)  which <em>extends</em> the discrete domain of the original function to a continuous domain. We will define it as a weighted combination of evaluations of the original function at discrete points, or equivalently, as the expected value of the function \(f\) over a distribution of sets encoded by \(\mathbf{x}\).</h3>
<p><img src="/images/extensions/pencil_2.png" alt="image description" /></p>

<p>That means that we will be going from a function defined on the corners of the hypercube \(\{0,1\}^n\) to a function defined on the whole hypercube \([0,1]^n\).
The main objective of the paper is to provide a foundation for this approach. It is a general framework for constructing continuous extensions of discrete functions defined on sets, that can be <em>deterministically</em> computed, even when we’re only given black-box access to \(f\). The paper presents multiple extensions that originate from a common mathematical formulation. Some are already known like the Lovász extension, and others are new, like the bounded cardinality Lovász extension. Furthermore, 
we provide a way to not only extend to continuous domains, but also onto <em>high-dimensional</em> ones. We will explore this in an upcoming post (part 2 of the series).</p>
<hr />

<h2 id="scalar-extensions-explained">Scalar extensions explained</h2>
<p>We call  \(\mathfrak{F}\) a scalar extension of a function \(f\), if  \(\mathfrak{F}(\mathbf{1}_S) = f(S)\) for all \(S\) in the domain of \(f\). For example,  \(\mathfrak{F}(\mathbf{0}) = f(\emptyset)\), i.e., the extension evaluated at the origin (all-zeros vector) should correspond to \(f\) being evaluated at the empty set.</p>

<h3 id="how-can-you-compute--mathfrakf">How can you compute  \(\mathfrak{F}\)?</h3>
<p>There is a simple trick to defining \(\mathfrak{F}\). As explained earlier, we can view \(\mathbf{x}\) as encoding a distribution over sets.
 To do this, we can express any continuous point in the n-hypercube \(\mathbf{x} \in [0,1]^n\) in the following way:</p>
<h4 id="displaystyle--mathbfx--sum_i-a_i-mathbf1_s_i-quad-displaystyle-sum_i-a_i--1">\(\displaystyle  \mathbf{x} = \sum_{i} a_i \mathbf{1}_{S_i}, \quad \displaystyle \sum_i a_i = 1.\)</h4>
<p>In other words, for every continuous point in the hypercube, we can find certain corners of the hypercube and express said point as a convex combination of those corners. This defines a distribution:</p>
<h4 id="mathbfx---displaystylemathbbe_s-sim-mathbfp_xs">\(\mathbf{x} =  \displaystyle\mathbb{E}_{S \sim \mathbf{p_x}}[S]\).</h4>
<p>Here \(\mathbf{p_x}\) is the probability distribution induced by \(\mathbf{x}\). This distribution is fully described by the coefficients \(a_i\) in the convex combination.
Once we have \(S_i\) and \(a_i\) defining \(\mathfrak{F}\)  is simple:</p>
<h4 id="mathfrakfmathbfx--triangleq-displaystylesum_i-a_i-fs_i--mathbbe_s-sim-mathbfp_xfs">\(\mathfrak{F}(\mathbf{x})  \triangleq \displaystyle\sum_{i} a_i f({S_i}) = \mathbb{E}_{S \sim \mathbf{p_x}}[f(S)]\).</h4>
<p>The distribution is supported only on sets \(S_i\) and each set has a corresponding probability of \(a_i\).
Intuitively, the value of the extension at the continuous point is just a weighted combination of the values of the original function \(f\) at the corners that form the convex combination of \(\mathbf{x}\). Furthermore, the weights of the weighted combination are precisely the same weights used to express \(\mathbf{x}\) as a convex combination of hypercube corners.</p>

<p>A large chunk of the paper is dedicated to properly formalizing this trick. Obviously, I will keep things simple here so I won’t get into all that. I encourage the curious reader to check out the paper.
Now, there are a couple of questions that naturally have to be addressed. One has to do with how we find those sets \(S_i\) and their coefficients \(a_i\). Is it computationally tractable? Can we do it fast? 
The other has to do with whether this thing is differentiable at all? 
Tha answer to all those questions is, modulo certain disclaimers, yes.</p>

<h3 id="how-can-we-backpropagate-through-mathfrakfmathbfx">How can we backpropagate through \(\mathfrak{F}(\mathbf{x})\)?</h3>
<p>The trick for this is simple. As long as \(a_i = g(\mathbf{x})\), and \(g\) is some continuous function of \(\mathbf{x}\), then gradients can just go through
the coefficients \(a_i\) in the sum that defines \(\mathfrak{F}(\mathbf{x})\).</p>

<h3 id="how-do-we-find-sets-s_i-and-their-coefficients-a_i">How do we find sets \(S_i\) and their coefficients \(a_i\)?</h3>
<p>In the paper we provide multiple examples of scalar extensions. Each one comes with its own way of computing sets \(S_i\) and their probabilities \(a_i\). Crucially, the coefficients \(a_i\) depend continuously on \(\mathbf{x}\) which allows us to do backpropagation.  The ‘cheapest’ extensions that require only black-box access to the function \(f\) are the Lovász extension, the bounded-cardinality Lovász extension, the singleton, and the permutation/involutory extensions.
These all require \(n+1\) sets (including the empty set) and coefficients.  Before I go into specific extensions and how to compute them, I want to emphasize that the key point to remember is that you could find your own extensions by figuring out ways to express continuous points as convex combinations of discrete points. I may discuss some general strategies for this in a future post but for now I will just leave it at that.</p>
<hr />

<h2 id="in-practice-the-lovász-extension">In practice: The Lovász extension</h2>
<p>The Lovász extension is well known in the fields of discrete analysis/optimization and submodularity. It has various particularly nice properties but perhaps the most important one is that iff \(f\) is a <a href="https://en.wikipedia.org/wiki/Submodular_set_function">submodular function</a>, then the Lovász extension of \(f\) is convex. Examples of submodular functions include graph cuts, coverage functions, rank functions, and so on. 
Computing the Lovász extension is straightforward.
First, we index the entries of \(\mathbf{x}\) in sorted, decreasing order: \(x_i \geq x_{i+1}\) for \(i=1,2,\dots , n-1\). That means that \(x_1\) corresponds to the dimension with the largest entry in \(\mathbf{x}\), \(x_2\) to the second largest, and so on.
The coefficients and the sets of the Lovász extension are then defined as follows:</p>
<h3 id="a_i--x_i---x_i1">\(a_i = x_i - x_{i+1}\)</h3>
<h3 id="s_i--1i-">\(S_i = \{1:i \}\).</h3>
<p>Here, I’m using a bit of coding notation with \(1:i\) to indicate “all elements up to \(i\)”.
Given the sets and their coefficients, the Lovász extension is computed by</p>
<h3 id="mathfrakfmathbfx--displaystyle-sum_i1n--x_i---x_i1f-1-i--">\(\mathfrak{F}(\mathbf{x}) = \displaystyle \sum_{i=1}^{n}  (x_i - x_{i+1})f( \{1: i \} )\).</h3>
<p>Clearly, \(a_i\) are differentiable with respect to \(\mathbf{x}\) as they’re just pairwise differences of the coordinates of \(\mathbf{x}\).
To make things concrete, let’s do the calculation to find sets and coefficients for our example vector from before: \(\mathbf{x} = \begin{bmatrix} 0.3 &amp; 0.5 &amp; 0.2\end{bmatrix}\).
Based on the ranking of the elements, we will have the following sets</p>
<h3 id="1_s_1--beginbmatrix-0--1--0-endbmatrix-1_s_2--beginbmatrix-1--1--0-endbmatrix-1_s_3--beginbmatrix-1--1--1-endbmatrix">\(1_{S_1} = \begin{bmatrix} 0 &amp; 1 &amp; 0 \end{bmatrix}, 1_{S_2} = \begin{bmatrix} 1 &amp; 1 &amp; 0 \end{bmatrix}, 1_{S_3} = \begin{bmatrix} 1 &amp; 1 &amp; 1 \end{bmatrix}\),</h3>
<p>and the following coefficients</p>
<h3 id="a_1--05-03--02">\(a_1 = 0.5-0.3 = 0.2,\)</h3>
<h3 id="a_2--03-02--01">\(a_2 = 0.3-0.2 = 0.1,\)</h3>
<h3 id="a_3--02-">\(a_3 = 0.2\) .</h3>
<p>It is easy to verify that \(\mathbf{x} = \sum_{i} a_i \mathbf{1}_{S_i}\). One might notice that \(\sum_i a_i  &lt;1\) in this case, even though I initially said that we need a sum to one. Thankfully, that’s not a problem because we can allocate the remaining probability mass to the empty set. By convention \(f(\emptyset) = 0\) so that term just cancels out. Therefore, we don’t strictly need the sum to 1, \(\sum_i a_i \leq 1\) can also be fine.</p>

<h2 id="converting-discrete-objectives-to-loss-functions-for-combinatorial-optimization-and-beyond">Converting discrete objectives to loss functions for combinatorial optimization and beyond</h2>
<p>A standard use case for extensions in practice is when we have some kind of quantity of interest that is defined over sets of objects and we would like to find a set that optimizes it. This is a sufficiently general setting that could encompass graph and combinatorial problems, classification problems, NLP problems, etc. Extensions can let us do that by finding the continuous version of that quantity through \(\mathfrak{F}\) and then backpropagating to find representations that optimize it.</p>

<h2 id="combinatorial-objectives">Combinatorial objectives</h2>
<p>Let’s look at a simple application of extensions to combinatorial optimization. Consider the graph cut function. It is a submodular set function, that given a set \(S\) of nodes in an input graph \(G\), it counts the number of edges that have one endpoint inside \(S\) and one endpoint outside of \(S\) in the graph. It is known that finding a set that maximizes the graph cut is an NP-Hard problem. Minimizing it is by default in \(P\) (can you guess why?), however adding a simple cardinality constraint can make minimization NP-Hard as well. A way to tackle the problem of optimizing the cut (either min or max) could be to provide a graph instance on \(n\) nodes to a neural network and then generate some scores for the nodes of the graph \(\mathbf{x} \in [0,1]^n\). That’s where the extensions come in. Here we can use the extension of the graph cut function as a loss function to optimize. Then we can backpropagate through the neural network scores \(\mathbf{x}\) and update the parameters of the network using the extension as a loss function. Normally, that wouldn’t be possible because we wouldn’t be able to backpropagate through an arbitrary set function.</p>

<p>Now, the graph cut function happens to admit a bunch of continuous relaxations that are well known. One of those is the graph total variation \(TV(\mathbf{x};G) = \displaystyle\sum_{(x_i&gt;x_j)} (x_i-x_j)w_{i,j}\), where \(w_{i,j}\) is the weight for any edge \((i,j)\) in the graph \(G\). It turns out that the Lovász Extension of the graph cut function is precisely the TV function so this is a case where a bespoke relaxation is naturally absorbed in our framework. However, the same trick could be done for any other combinatorial problem. Take its objective function \(g(S)\) and a function that encodes the constraint \(c(S)\). For instance, for the maximum clique problem, \(g(S)\) is the number of nodes of \(S\), which we seek to maximize. The constraint \(c(S)\) on the other hand can just be a binary signal, it can be defined as follows:</p>
<h3 id="cs--begincases-1--textif-the-set-is-a-clique--0--text-otherwise-endcases">\(c(S) = \begin{cases} 1 \; \text{if the set is a clique,} \\ 0 \; \text{ otherwise.} \end{cases}\)</h3>
<p>Then we may combine \(c\) and \(g\) into \(f(S) = c(S)g(S)\). This is now a discrete set function which we can attempt to maximize in order to solve the maximum clique problem. We compute its continuous extension and use that as a loss function in order to find a score vector \(\mathbf{x}\) that encodes a distribution of sets \(S\) that best solves the problem.</p>

<h2 id="putting-it-all-together-a-recipe-for-solving-problems-with-extensions">Putting it all together: A recipe for solving problems with extensions</h2>
<p>To summarize, here are 4 steps to start solving problems with extensions. Assuming you have some discrete function \(f: \{0,1\}^n \rightarrow \mathbb{R}\) and you are looking for subsets of \(n\) objects that give you the optimal value for that function.</p>
<ul>
  <li>Step 1: Get a neural network and an input instance (image, graph, whatever).</li>
  <li>Step 2: Generate scores \(\mathbf{x} \in [0,1]^n\). The dimension \(n\) may be the number of nodes of a graph, the number of classes for classification, etc.</li>
  <li>Step 3: Compute an extension \(\mathfrak{F}\) of the function \(f\). Use \(\mathfrak{F}\) (with an appropriate sign for minimization/maximization) as your loss function.</li>
  <li>Step 4: To decide on a set for the solution to the problem, generate the sets \(S\) of the extension and pick whichever gives you the best value for \(f\).</li>
</ul>

<p>That’s pretty much it. In the paper we apply those steps to do combinatorial optimization but we also show how they can be used for image classification by defining an extension for the discrete training error function (the possible input subsets there are just the \(n\) possible class labels that are represented by one-hot binary vectors). From brief discussions I’ve had 
at NeurIPS 2022, it seems like this kind of trick could be applied to other settings like NLP or VAEs. Those applications are left as an exercise to the reader :)</p>
<hr />

<h2 id="conclusion-and-part-2-neural-extensions">Conclusion and Part 2: Neural Extensions</h2>
<p>Conceptually, this post has dealt with the first half of the paper. I intentionally avoided discussing the meaning of the word <em>scalar</em> in the subtitle of the post. The characterization of <em>scalar</em> set function extensions has to do with the domain of the extension. If the extensions work on the hypercube like \(\{0,1\}^n \rightarrow  [0,1]^n\), we are assigning a single scalar continuous score to each item among \(n\) items. In part 2 of this series, we will see how we can stretch the definition of extensions to allow for extensions of the form \(\{0,1\}^n \rightarrow  [0,1]^{n \times d}\), i.e., \(d\)-dimensional embeddings for each item, which is usually the kind of representation that the layers of a neural network operate with (\(d\) would just be the width of a NN). 
But that’s a story for another time. Until then, I hope this has been helpful.</p>


            </div>

            <!--- DIVIDING LINE -->
            <hr>

            <!-- POST TAGS -->
            <div class="inline-tags">
                <span>
                    
                        <a href="/tags/#Learning with discrete functions">#Learning with discrete functions&nbsp;&nbsp;&nbsp;</a>
                    
                        <a href="/tags/#Neural Networks">#Neural Networks&nbsp;&nbsp;&nbsp;</a>
                    
                        <a href="/tags/#Combinatorial optimization">#Combinatorial optimization&nbsp;&nbsp;&nbsp;</a>
                    
                </span>
            </div>

            <br>

            <!-- POST DATE -->
            <div class="post-date">
                December 18, 2022
            </div>
        </article>
    </div>
</body>

<!-- FOOTER -->
<footer>
    <div class="footer-wrapper">
        <footer role="contentinfo">
            <span>
    &copy; 2022 Nikolaos Karalias.<br>Powered by <a target="_blank" href="https://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a target="_blank" href="https://github.com/benradford/Slate-and-Simple-Jekyll-Theme">Slate+Simple</a> theme.
</span>

        </footer>
    </div>
</footer>
</html>
